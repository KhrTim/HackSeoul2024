{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca268d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google-api-python-client\n",
      "  Obtaining dependency information for google-api-python-client from https://files.pythonhosted.org/packages/f0/41/957e29b392728ba94d1df652e2f3ce59022a6d7bb0164575c016ad204a52/google_api_python_client-2.142.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading google_api_python_client-2.142.0-py2.py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting httplib2<1.dev0,>=0.19.0 (from google-api-python-client)\n",
      "  Obtaining dependency information for httplib2<1.dev0,>=0.19.0 from https://files.pythonhosted.org/packages/a8/6c/d2fbdaaa5959339d53ba38e94c123e4e84b8fbc4b84beb0e70d7c1608486/httplib2-0.22.0-py3-none-any.whl.metadata\n",
      "  Downloading httplib2-0.22.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0 (from google-api-python-client)\n",
      "  Obtaining dependency information for google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0 from https://files.pythonhosted.org/packages/bb/fb/9af9e3f2996677bdda72734482934fe85a3abde174e5f0783ac2f817ba98/google_auth-2.34.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading google_auth-2.34.0-py2.py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting google-auth-httplib2<1.0.0,>=0.2.0 (from google-api-python-client)\n",
      "  Obtaining dependency information for google-auth-httplib2<1.0.0,>=0.2.0 from https://files.pythonhosted.org/packages/be/8a/fe34d2f3f9470a27b01c9e76226965863f153d5fbe276f83608562e49c04/google_auth_httplib2-0.2.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5 (from google-api-python-client)\n",
      "  Obtaining dependency information for google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5 from https://files.pythonhosted.org/packages/44/99/daa3541e8ecd7d8b7907b714ba92126097a976b5b3dbabdb5febdcf08554/google_api_core-2.19.1-py3-none-any.whl.metadata\n",
      "  Downloading google_api_core-2.19.1-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting uritemplate<5,>=3.0.1 (from google-api-python-client)\n",
      "  Obtaining dependency information for uritemplate<5,>=3.0.1 from https://files.pythonhosted.org/packages/81/c0/7461b49cd25aeece13766f02ee576d1db528f1c37ce69aee300e075b485b/uritemplate-4.1.1-py2.py3-none-any.whl.metadata\n",
      "  Downloading uritemplate-4.1.1-py2.py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting googleapis-common-protos<2.0.dev0,>=1.56.2 (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client)\n",
      "  Obtaining dependency information for googleapis-common-protos<2.0.dev0,>=1.56.2 from https://files.pythonhosted.org/packages/02/48/87422ff1bddcae677fb6f58c97f5cfc613304a5e8ce2c3662760199c0a84/googleapis_common_protos-1.63.2-py2.py3-none-any.whl.metadata\n",
      "  Downloading googleapis_common_protos-1.63.2-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0.dev0,>=3.19.5 (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client)\n",
      "  Obtaining dependency information for protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0.dev0,>=3.19.5 from https://files.pythonhosted.org/packages/a4/30/cb5395acd5f65edc0dee77bdd134fe556c52fade2ad3ea9ac2676d01effe/protobuf-5.27.3-cp310-abi3-win_amd64.whl.metadata\n",
      "  Downloading protobuf-5.27.3-cp310-abi3-win_amd64.whl.metadata (592 bytes)\n",
      "Collecting proto-plus<2.0.0dev,>=1.22.3 (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client)\n",
      "  Obtaining dependency information for proto-plus<2.0.0dev,>=1.22.3 from https://files.pythonhosted.org/packages/7c/6f/db31f0711c0402aa477257205ce7d29e86a75cb52cd19f7afb585f75cda0/proto_plus-1.24.0-py3-none-any.whl.metadata\n",
      "  Downloading proto_plus-1.24.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in c:\\users\\doitg\\anaconda3\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2.31.0)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client)\n",
      "  Obtaining dependency information for cachetools<6.0,>=2.0.0 from https://files.pythonhosted.org/packages/a4/07/14f8ad37f2d12a5ce41206c21820d8cb6561b728e51fad4530dff0552a67/cachetools-5.5.0-py3-none-any.whl.metadata\n",
      "  Downloading cachetools-5.5.0-py3-none-any.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\doitg\\anaconda3\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client) (0.2.8)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client)\n",
      "  Obtaining dependency information for rsa<5,>=3.1.4 from https://files.pythonhosted.org/packages/49/97/fa78e3d2f65c02c8e1268b9aba606569fe97f6c8f7c2d74394553347c145/rsa-4.9-py3-none-any.whl.metadata\n",
      "  Downloading rsa-4.9-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in c:\\users\\doitg\\anaconda3\\lib\\site-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client) (3.0.9)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\doitg\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client) (0.4.8)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\doitg\\anaconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\doitg\\anaconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\doitg\\anaconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\doitg\\anaconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2023.11.17)\n",
      "Downloading google_api_python_client-2.142.0-py2.py3-none-any.whl (12.2 MB)\n",
      "   ---------------------------------------- 0.0/12.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.2 MB 1.3 MB/s eta 0:00:10\n",
      "   ---------------------------------------- 0.1/12.2 MB 1.7 MB/s eta 0:00:08\n",
      "   - -------------------------------------- 0.4/12.2 MB 2.8 MB/s eta 0:00:05\n",
      "   -- ------------------------------------- 0.7/12.2 MB 3.8 MB/s eta 0:00:04\n",
      "   --- ------------------------------------ 1.2/12.2 MB 5.4 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 1.9/12.2 MB 7.1 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 2.7/12.2 MB 8.6 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 3.4/12.2 MB 9.8 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 4.2/12.2 MB 10.3 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 5.0/12.2 MB 11.0 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 5.8/12.2 MB 11.9 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 6.4/12.2 MB 12.0 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 7.2/12.2 MB 12.5 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 7.8/12.2 MB 12.2 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 8.5/12.2 MB 12.6 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 9.3/12.2 MB 13.0 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 9.9/12.2 MB 12.9 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 10.8/12.2 MB 15.6 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 11.5/12.2 MB 16.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.2/12.2 MB 16.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.2/12.2 MB 16.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.2/12.2 MB 13.9 MB/s eta 0:00:00\n",
      "Downloading google_api_core-2.19.1-py3-none-any.whl (139 kB)\n",
      "   ---------------------------------------- 0.0/139.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 139.4/139.4 kB 8.6 MB/s eta 0:00:00\n",
      "Downloading google_auth-2.34.0-py2.py3-none-any.whl (200 kB)\n",
      "   ---------------------------------------- 0.0/200.9 kB ? eta -:--:--\n",
      "   --------------------------------------- 200.9/200.9 kB 11.9 MB/s eta 0:00:00\n",
      "Downloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl (9.3 kB)\n",
      "Downloading httplib2-0.22.0-py3-none-any.whl (96 kB)\n",
      "   ---------------------------------------- 0.0/96.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 96.9/96.9 kB 5.8 MB/s eta 0:00:00\n",
      "Downloading uritemplate-4.1.1-py2.py3-none-any.whl (10 kB)\n",
      "Downloading cachetools-5.5.0-py3-none-any.whl (9.5 kB)\n",
      "Downloading googleapis_common_protos-1.63.2-py2.py3-none-any.whl (220 kB)\n",
      "   ---------------------------------------- 0.0/220.0 kB ? eta -:--:--\n",
      "   --------------------------------------- 220.0/220.0 kB 14.0 MB/s eta 0:00:00\n",
      "Downloading proto_plus-1.24.0-py3-none-any.whl (50 kB)\n",
      "   ---------------------------------------- 0.0/50.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 50.1/50.1 kB ? eta 0:00:00\n",
      "Downloading protobuf-5.27.3-cp310-abi3-win_amd64.whl (426 kB)\n",
      "   ---------------------------------------- 0.0/426.9 kB ? eta -:--:--\n",
      "   --------------------------------------- 426.9/426.9 kB 26.0 MB/s eta 0:00:00\n",
      "Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Installing collected packages: uritemplate, rsa, protobuf, httplib2, cachetools, proto-plus, googleapis-common-protos, google-auth, google-auth-httplib2, google-api-core, google-api-python-client\n",
      "Successfully installed cachetools-5.5.0 google-api-core-2.19.1 google-api-python-client-2.142.0 google-auth-2.34.0 google-auth-httplib2-0.2.0 googleapis-common-protos-1.63.2 httplib2-0.22.0 proto-plus-1.24.0 protobuf-5.27.3 rsa-4.9 uritemplate-4.1.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google-auth-oauthlib\n",
      "  Obtaining dependency information for google-auth-oauthlib from https://files.pythonhosted.org/packages/1a/8e/22a28dfbd218033e4eeaf3a0533b2b54852b6530da0c0fe934f0cc494b29/google_auth_oauthlib-1.2.1-py2.py3-none-any.whl.metadata\n",
      "  Downloading google_auth_oauthlib-1.2.1-py2.py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: google-auth-httplib2 in c:\\users\\doitg\\anaconda3\\lib\\site-packages (0.2.0)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in c:\\users\\doitg\\anaconda3\\lib\\site-packages (from google-auth-oauthlib) (2.34.0)\n",
      "Collecting requests-oauthlib>=0.7.0 (from google-auth-oauthlib)\n",
      "  Obtaining dependency information for requests-oauthlib>=0.7.0 from https://files.pythonhosted.org/packages/3b/5d/63d4ae3b9daea098d5d6f5da83984853c1bbacd5dc826764b249fe119d24/requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: httplib2>=0.19.0 in c:\\users\\doitg\\anaconda3\\lib\\site-packages (from google-auth-httplib2) (0.22.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\doitg\\anaconda3\\lib\\site-packages (from google-auth>=2.15.0->google-auth-oauthlib) (5.5.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\doitg\\anaconda3\\lib\\site-packages (from google-auth>=2.15.0->google-auth-oauthlib) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\doitg\\anaconda3\\lib\\site-packages (from google-auth>=2.15.0->google-auth-oauthlib) (4.9)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in c:\\users\\doitg\\anaconda3\\lib\\site-packages (from httplib2>=0.19.0->google-auth-httplib2) (3.0.9)\n",
      "Collecting oauthlib>=3.0.0 (from requests-oauthlib>=0.7.0->google-auth-oauthlib)\n",
      "  Obtaining dependency information for oauthlib>=3.0.0 from https://files.pythonhosted.org/packages/7e/80/cab10959dc1faead58dc8384a781dfbf93cb4d33d50988f7a69f1b7c9bbe/oauthlib-3.2.2-py3-none-any.whl.metadata\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl.metadata (7.5 kB)\n",
      "Requirement already satisfied: requests>=2.0.0 in c:\\users\\doitg\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib) (2.31.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\doitg\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-auth-oauthlib) (0.4.8)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\doitg\\anaconda3\\lib\\site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\doitg\\anaconda3\\lib\\site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\doitg\\anaconda3\\lib\\site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\doitg\\anaconda3\\lib\\site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib) (2023.11.17)\n",
      "Downloading google_auth_oauthlib-1.2.1-py2.py3-none-any.whl (24 kB)\n",
      "Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "   ---------------------------------------- 0.0/151.7 kB ? eta -:--:--\n",
      "   ------------------ --------------------- 71.7/151.7 kB 1.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 151.7/151.7 kB 1.8 MB/s eta 0:00:00\n",
      "Installing collected packages: oauthlib, requests-oauthlib, google-auth-oauthlib\n",
      "Successfully installed google-auth-oauthlib-1.2.1 oauthlib-3.2.2 requests-oauthlib-2.0.0\n",
      "Collecting youtube-transcript-api\n",
      "  Obtaining dependency information for youtube-transcript-api from https://files.pythonhosted.org/packages/52/42/5f57d37d56bdb09722f226ed81cc1bec63942da745aa27266b16b0e16a5d/youtube_transcript_api-0.6.2-py3-none-any.whl.metadata\n",
      "  Downloading youtube_transcript_api-0.6.2-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\doitg\\anaconda3\\lib\\site-packages (from youtube-transcript-api) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\doitg\\anaconda3\\lib\\site-packages (from requests->youtube-transcript-api) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\doitg\\anaconda3\\lib\\site-packages (from requests->youtube-transcript-api) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\doitg\\anaconda3\\lib\\site-packages (from requests->youtube-transcript-api) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\doitg\\anaconda3\\lib\\site-packages (from requests->youtube-transcript-api) (2023.11.17)\n",
      "Downloading youtube_transcript_api-0.6.2-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: youtube-transcript-api\n",
      "Successfully installed youtube-transcript-api-0.6.2\n",
      "Requirement already satisfied: nltk in c:\\users\\doitg\\anaconda3\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: click in c:\\users\\doitg\\anaconda3\\lib\\site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: joblib in c:\\users\\doitg\\anaconda3\\lib\\site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\doitg\\anaconda3\\lib\\site-packages (from nltk) (2022.7.9)\n",
      "Requirement already satisfied: tqdm in c:\\users\\doitg\\anaconda3\\lib\\site-packages (from nltk) (4.65.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\doitg\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Collecting vaderSentiment\n",
      "  Obtaining dependency information for vaderSentiment from https://files.pythonhosted.org/packages/76/fc/310e16254683c1ed35eeb97386986d6c00bc29df17ce280aed64d55537e9/vaderSentiment-3.3.2-py2.py3-none-any.whl.metadata\n",
      "  Downloading vaderSentiment-3.3.2-py2.py3-none-any.whl.metadata (572 bytes)\n",
      "Requirement already satisfied: requests in c:\\users\\doitg\\anaconda3\\lib\\site-packages (from vaderSentiment) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\doitg\\anaconda3\\lib\\site-packages (from requests->vaderSentiment) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\doitg\\anaconda3\\lib\\site-packages (from requests->vaderSentiment) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\doitg\\anaconda3\\lib\\site-packages (from requests->vaderSentiment) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\doitg\\anaconda3\\lib\\site-packages (from requests->vaderSentiment) (2023.11.17)\n",
      "Downloading vaderSentiment-3.3.2-py2.py3-none-any.whl (125 kB)\n",
      "   ---------------------------------------- 0.0/126.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/126.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/126.0 kB ? eta -:--:--\n",
      "   --- ------------------------------------ 10.2/126.0 kB ? eta -:--:--\n",
      "   --- ------------------------------------ 10.2/126.0 kB ? eta -:--:--\n",
      "   ------------ -------------------------- 41.0/126.0 kB 217.9 kB/s eta 0:00:01\n",
      "   ------------------- ------------------- 61.4/126.0 kB 297.7 kB/s eta 0:00:01\n",
      "   -------------------------------------- 126.0/126.0 kB 462.8 kB/s eta 0:00:00\n",
      "Installing collected packages: vaderSentiment\n",
      "Successfully installed vaderSentiment-3.3.2\n"
     ]
    }
   ],
   "source": [
    "# Python 을 통해 Google API를 사용하기 위해서 라이브러리 다운로드\n",
    "!pip install google-api-python-client\n",
    "# Google 과 관련한 API를 사용하기 위해 필요한 모듈\n",
    "!pip install google-auth-oauthlib google-auth-httplib2\n",
    "# Youtube Captions 를 추출하기 위한 API를 사용하기 위해서 라이브러리 다운로드\n",
    "!pip install youtube-transcript-api\n",
    "!pip install nltk\n",
    "!pip install vaderSentiment\n",
    "!pip install spacy\n",
    "!pip install textblob\n",
    "!python -m spacy download en_core_web_sm\n",
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b64ad6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from googleapiclient.discovery import build\n",
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "from youtube_transcript_api.formatters import TextFormatter\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import spacy\n",
    "import re\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# OpenAI API 클라이언트 생성\n",
    "openai.api_key = 'YOUR_KEY'  # 자신의 OpenAI API 키 입력\n",
    "\n",
    "# YouTube API 클라이언트 생성\n",
    "api_key = 'YOUR_KEY'  # 자신의 YouTube API 키 입력\n",
    "youtube = build('youtube', 'v3', developerKey=api_key)\n",
    "\n",
    "# spaCy 모델 로드\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# 감정 분석기 초기화\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# 주제 관련 비디오 검색 함수\n",
    "def search_videos_by_keyword(keyword, region_code='KR', max_results=3):\n",
    "    numbers = [5, 10, 30, 50]  # 사용할 숫자 목록\n",
    "    prefixes = [\"Top\", \"Ranking\"]  # 사용할 접두사 목록\n",
    "\n",
    "    six_months_ago = datetime.now() - timedelta(days=180)\n",
    "    published_after = six_months_ago.isoformat(\"T\") + \"Z\"  # ISO 8601 형식으로 변환\n",
    "\n",
    "    search_results = {}\n",
    "\n",
    "    for number in numbers:\n",
    "        for prefix in prefixes:\n",
    "            query = f\"{prefix} {number} {keyword} review\"\n",
    "\n",
    "            search_request = youtube.search().list(\n",
    "                part='snippet',\n",
    "                type='video',\n",
    "                q=query,\n",
    "                regionCode=region_code,\n",
    "                maxResults=max_results,\n",
    "                publishedAfter=published_after\n",
    "            )\n",
    "\n",
    "            search_response = search_request.execute()\n",
    "\n",
    "            video_ids = [item['id']['videoId'] for item in search_response['items']]\n",
    "\n",
    "            video_request = youtube.videos().list(\n",
    "                part='snippet,statistics',\n",
    "                id=','.join(video_ids)\n",
    "            )\n",
    "\n",
    "            video_response = video_request.execute()\n",
    "\n",
    "            for item in video_response['items']:\n",
    "                video_id = item['id']\n",
    "                title = item['snippet']['title']\n",
    "                view_count = int(item['statistics']['viewCount'])\n",
    "                published_date = item['snippet']['publishedAt']\n",
    "\n",
    "                try:\n",
    "                    transcript = YouTubeTranscriptApi.get_transcript(video_id)\n",
    "                    formatter = TextFormatter()\n",
    "                    captions = formatter.format_transcript(transcript)\n",
    "                    captions = split_into_sentences(captions)\n",
    "                except Exception as e:\n",
    "                    captions = f\"No captions available or error occurred: {e}\"\n",
    "\n",
    "                search_results[video_id] = {\n",
    "                    'title': title,\n",
    "                    'views': view_count,\n",
    "                    'published_date': published_date,\n",
    "                    'captions': captions\n",
    "                }\n",
    "\n",
    "    return search_results\n",
    "\n",
    "# 자막을 문장 단위로 분리하는 함수\n",
    "def split_into_sentences(captions):\n",
    "    sentences = re.split(r'(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?)\\s', captions)\n",
    "    return \" \".join(sentences)\n",
    "\n",
    "# OpenAI GPT-4 모델을 사용하여 제품명 추출 함수\n",
    "def extract_product_names_with_gpt(captions):\n",
    "    try:\n",
    "        response = openai.Completion.create(\n",
    "            model=\"gpt-4o\",\n",
    "            prompt=f\"Extract product names from the following text: {captions}\",\n",
    "            max_tokens=100,\n",
    "            n=1,\n",
    "            stop=None,\n",
    "            temperature=0.5\n",
    "        )\n",
    "        product_names = response.choices[0].text.strip().split(\",\")\n",
    "        product_names = [name.strip() for name in product_names]\n",
    "        return product_names\n",
    "    except Exception as e:\n",
    "        print(f\"Error in GPT-4o API call: {e}\")\n",
    "        return []\n",
    "\n",
    "# 제품 리뷰 자막에서 주요 특징(Aspect) 추출 함수\n",
    "def extract_aspects(captions, top_n=5):\n",
    "    doc = nlp(captions)\n",
    "    nouns = [chunk.text for chunk in doc.noun_chunks]\n",
    "\n",
    "    vectorizer = TfidfVectorizer(stop_words='english')\n",
    "    X = vectorizer.fit_transform(nouns)\n",
    "    tfidf_scores = dict(zip(vectorizer.get_feature_names_out(), X.sum(axis=0).tolist()[0]))\n",
    "    sorted_tfidf = sorted(tfidf_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    aspects = [aspect for aspect, score in sorted_tfidf[:top_n]]\n",
    "    return aspects\n",
    "\n",
    "# ABSA(Aspect-Based Sentiment Analysis) 함수\n",
    "def analyze_sentiment(captions, aspects):\n",
    "    aspect_sentiments = {}\n",
    "    for aspect in aspects:\n",
    "        sentences = [sent for sent in captions.split('. ') if aspect in sent]\n",
    "        sentiment_scores = [analyzer.polarity_scores(sent)['compound'] for sent in sentences]\n",
    "        avg_sentiment = sum(sentiment_scores) / len(sentiment_scores) if sentiment_scores else 0\n",
    "        aspect_sentiments[aspect] = avg_sentiment\n",
    "    return aspect_sentiments\n",
    "\n",
    "# 제품 자체의 감정 점수를 계산하는 함수 (특성의 감정 점수 기반)\n",
    "def calculate_product_sentiment_from_aspects(sentiment_scores, weight=1.0):\n",
    "    if sentiment_scores:\n",
    "        avg_sentiment = (sum(sentiment_scores.values()) / len(sentiment_scores)) * weight\n",
    "    else:\n",
    "        avg_sentiment = 0\n",
    "    return avg_sentiment\n",
    "\n",
    "# 자막 데이터를 기반으로 제품명, 특징 및 감성 분석을 수행하는 함수\n",
    "def process_single_caption(video_id, captions, weight=1.0):\n",
    "    print(f\"\\nProcessing Video ID: {video_id}\")\n",
    "    product_names = extract_product_names_with_gpt(captions)\n",
    "\n",
    "    if not product_names:\n",
    "        print(\"No product names found.\")\n",
    "        return\n",
    "\n",
    "    product_sentiments = {}\n",
    "\n",
    "    print(\"Extracted product names:\")\n",
    "    for product in product_names:\n",
    "        print(f\"Product: {product}\")\n",
    "\n",
    "    for product in product_names:\n",
    "        print(f\"\\nAnalyzing product: {product}\")\n",
    "        product_section = re.findall(f\"{product}.*?(?=\\\\n[A-Z]|$)\", captions, re.DOTALL)\n",
    "        if product_section:\n",
    "            product_section = product_section[0]\n",
    "            aspects = extract_aspects(product_section)\n",
    "            sentiment_scores = analyze_sentiment(product_section, aspects)\n",
    "            product_sentiment = calculate_product_sentiment_from_aspects(sentiment_scores, weight)\n",
    "\n",
    "            product_sentiments[product] = product_sentiment\n",
    "\n",
    "            print(f\"\\nProduct Sentiment: {product_sentiment}\")\n",
    "            print(\"\\nExtracted aspects and their sentiment scores:\")\n",
    "            for aspect, sentiment in sentiment_scores.items():\n",
    "                print(f\"Aspect: {aspect}, Sentiment: {sentiment}\")\n",
    "        else:\n",
    "            print(f\"No detailed section found for product: {product}\")\n",
    "\n",
    "    sorted_products = sort_products_by_sentiment(product_sentiments)\n",
    "    print(\"\\nProducts sorted by sentiment (descending):\")\n",
    "    for product, sentiment in sorted_products:\n",
    "        print(f\"Product: {product}, Sentiment: {sentiment}\")\n",
    "\n",
    "# 여러 동영상 자막을 처리하는 함수\n",
    "def process_multiple_captions(captions_data, weights):\n",
    "    final_results = []\n",
    "    for video_id, data in captions_data.items():\n",
    "        captions = data['captions']\n",
    "        weight = weights.get(video_id, 1.0)\n",
    "        process_single_caption(video_id, captions, weight)\n",
    "        final_results.append((video_id, data['title'], weight))\n",
    "\n",
    "    return final_results\n",
    "\n",
    "# 가중치를 동적으로 계산하는 함수 (조회수 기반)\n",
    "def calculate_dynamic_weights(captions_data):\n",
    "    max_views = max(data['views'] for data in captions_data.values())\n",
    "    weights = {}\n",
    "    for video_id, data in captions_data.items():\n",
    "        view_count = data['views']\n",
    "        weights[video_id] = view_count / max_views\n",
    "    return weights\n",
    "\n",
    "# 제품 및 감정 점수 정렬 함수\n",
    "def sort_products_by_sentiment(product_sentiments):\n",
    "    return sorted(product_sentiments.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# 최종 결과 출력 및 정렬 함수\n",
    "def print_final_results(final_results):\n",
    "    sorted_results = sorted(final_results, key=lambda x: x[2], reverse=True)\n",
    "\n",
    "    print(\"\\nFinal Results (Sorted by Product Sentiment):\")\n",
    "    for video_id, title, sentiment in sorted_results:\n",
    "        print(f\"Video ID: {video_id}, Title: {title}, Sentiment: {sentiment}\")\n",
    "\n",
    "# 검색어로 비디오 검색 및 자막 데이터 가져오기\n",
    "keyword = category\n",
    "captions_data = search_videos_by_keyword(keyword)\n",
    "\n",
    "# 가중치 계산\n",
    "weights = calculate_dynamic_weights(captions_data)\n",
    "\n",
    "# 여러 자막 데이터 처리 후 최종 결과 출력\n",
    "final_results = process_multiple_captions(captions_data, weights)\n",
    "print_final_results(final_results)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
